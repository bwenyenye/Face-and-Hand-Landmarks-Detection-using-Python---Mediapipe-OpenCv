# -*- coding: utf-8 -*-
"""Face and Hand Landmarks Detection using Python - Mediapipe, OpenCv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d3ohqewWwTtkKmLO5FCPCFYZ0eNfUL8n

We will be using mediapipe python library to detect face and hand landmarks. 

We shall be using a Holistic model from mediapipe solutions to detect all the face and hand landmarks.


We will also be seeing how we can access different landmarks of the face and hands which can be used for different computer vision applications such as sign language detection, drowsiness detection and so on.

## Requried Libraries

* Mediapipe - a cross platform developed by Google in 2012 to provide ready to use Machine Learning solutions for computer vision tasks.

* OpenCV library in python is a computer vision library that is widely used for image analysis, image processing, detection, recogntion and so on.

# Installing required libraries
"""

#CHECKING LATEST VERSION OF MEDIAPIPE

!pip show mediapipe

!pip install opencv-python
!pip install mediapipe==0.8.9.1

"""# Importing Libraries"""

import cv2
import time
import mediapipe as mp



"""# Initializing Holistic model and Drawing utils for detecting and drawing landmarks on the image"""

# Grabbing the Holistic Model from Mediapipe and 
# Initializing the model

mp_holistic = mp.solutions.holistic
holistic_model = mp_holistic.Holistic(
    min_detection_confidence = 0.5,
    min_tracking_confidence = 0.5
)

# Initializing the drawing utils for drawing the facial landmarks on image
mp_drawing = mp.solutions.drawing_utils

"""Here's what's happening in the code:

We import the mediapipe library and assign it an alias of mp.

We create an object called mp_holistic that represents the holistic module in mediapipe.solutions. This module contains the Holistic class that we'll use to create our model.

We initialize our Holistic model by creating an instance of the Holistic class from the mp_holistic object. We also set the min_detection_confidence and min_tracking_confidence parameters to 0.5. These parameters control the minimum confidence scores required for the model to detect and track different parts of the body.

With this code, you can now use the holistic_model object to process images or video frames and extract information about the pose, face, and hand landmarks. For example, you can pass an image to the model's process() method:



"""

#import cv2

# Read an image using OpenCV
#image = cv2.imread("my_image.jpg")

# Process the image using the Holistic model
#result = holistic_model.process(image)

"""This will return a HolisticResults object that contains information about the detected landmarks and poses in the image. You can then extract this information using the various methods available on the HolisticResults object

Let us look into the parameters for the Holistic model:
"""

# Holistic(
#  static_image_mode=False, 
#  model_complexity=1, 
#  smooth_landmarks=True, 
#  min_detection_confidence=0.5, 
#  min_tracking_confidence=0.5
#)

"""* **static_image_mode**: It is used to specify whether the input images must be treated as static images or as a video stream. The default value is False.

* **model_complexity:** It is used to specify the complexity of the pose landmark model: 0, 1, or 2. As the model complexity of the model increases the landmark accuracy and latency increase. The default value is 1.

* **smooth_landmarks:** This parameter is used to reduce the jitter in the prediction by filtering pose landmarks across different input images. The default value is True.

* **min_detection_confidence:** It is used to specify the minimum confidence value with which the detection from the person-detection model needs to be considered as successful. Can specify a value in [0.0,1.0]. The default value is 0.5.

* **min_tracking_confidence:** It is used to specify the minimum confidence value with which the detection from the landmark-tracking model must be considered as successful. Can specify a value in [0.0,1.0]. The default value is 0.5.

# Detect Face and Hand Landmarks from the Image

Holistic model processes the image and produces landmarks for Face, Left hand, Right Hand and also detects the pose of the 

1. Capture the frames continuosly from the camera using OpenCv

2. Convert the BGR image to an RGB image and make predictions using initialized holistic model

3. The predictions made by the holistic model are saved in the result variable from which we can access the landmarks using results.face_landmarks, results.right_hand_landmarks, results.left_hand_landmarks respectively

4. Draw the detected landmarks on the image using the draw_landmarks function from drawing utils

5. Display the resulting image
"""

# (0) in VideoCapture is used to connect to your computer's default camera

capture = cv2.VideoCapture(0)

# Initializing current time and previous time for calculating frame per second (FPS)
previousTime = 0
currentTime = 0

while capture.isOpened():
    # capture frame by frame
    ret, frame = capture.read()

    # resizing the frame for better view
    frame = cv2.resize(frame, (800,600))

    #converting from BGR to RGB
    image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)

    # making predictions using holistic model
    # To improve image performance, optionally mark the image as not writeabke to
    #pass by reference
    image.flags.writeable = False
    results = holistic_model.process(image)
    image.flags.writeable = True

    # Converting back the RGB image to BGR
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
 
    # Drawing the Facial Landmarks
    mp_drawing.draw_landmarks(
      image,
      results.face_landmarks,
      mp_holistic.FACEMESH_CONTOURS,
      mp_drawing.DrawingSpec(
        color=(255,0,255),
        thickness=1,
        circle_radius=1
      ),
      mp_drawing.DrawingSpec(
        color=(0,255,255),
        thickness=1,
        circle_radius=1
      )
    )
 
    # Drawing Right hand Land Marks
    mp_drawing.draw_landmarks(
      image,
      results.right_hand_landmarks,
      mp_holistic.HAND_CONNECTIONS
    )
 
    # Drawing Left hand Land Marks
    mp_drawing.draw_landmarks(
      image,
      results.left_hand_landmarks,
      mp_holistic.HAND_CONNECTIONS
    )
     
    # Calculating the FPS
    currentTime = time.time()
    fps = 1 / (currentTime-previousTime)
    previousTime = currentTime
     
    # Displaying FPS on the image
    cv2.putText(image, str(int(fps))+" FPS", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)
 
    # Display the resulting image
    cv2.imshow("Facial and Hand Landmarks", image)
 
    # Enter key 'q' to break the loop
    if cv2.waitKey(5) & 0xFF == ord('q'):
        break
 
# When all the process is done
# Release the capture and destroy all windows
capture.release()
cv2.destroyAllWindows()

"""The holistic model produces 468 Face landmarks, 21 Left-Hand landmarks, and 21 Right-Hand landmarks. The individual landmarks can be accessed by specifying the index of the required landmark. Example: results.left_hand_landmarks.landmark[0].
 You can get the index of all the individual landmarks using the below code:
"""

# Code to access landmarks
for landmark in mp_holistic.HandLandmark:
	print(landmark, landmark.value)

print(mp_holistic.HandLandmark.WRIST.value)

